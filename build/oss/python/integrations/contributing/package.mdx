---
pagination_next: contributing/how_to/integrations/standard_tests
pagination_prev: contributing/how_to/integrations/index
title: Implement a package
---

This guide walks through the process of implementing a LangChain integration
package.

Integration packages are Python packages that can be installed with `pip install <your-package>`,
which contain classes that are compatible with LangChain's core interfaces.

This guide covers:

1. (Optional) How to bootstrap a new integration package
2. How to implement components, such as chat models and vector stores, that adhere
to the LangChain interface

## (Optional) bootstrapping a new integration package

In this section, there are two options for bootstrapping a new integration package, but you can use other tools if you prefer.

1. **langchain-cli**: This is a command-line tool that can be used to bootstrap a new integration package with a template for LangChain components and Poetry for dependency management.
2. **Poetry**: This is a Python dependency management tool that can be used to bootstrap a new Python package with dependencies. You can then add LangChain components to this package.

<Accordion title="Option 1: langchain-cli (recommended)">

In this guide, we will be using the `langchain-cli` to create a new integration package
from a template, which can be edited to implement your LangChain components.

### Prerequisites

- [GitHub](https://github.com) account
- [PyPi](https://pypi.org/) account

### Bootstrapping a new Python package with langchain-cli

First, install `langchain-cli` and `poetry`:

<CodeGroup>
```bash pip
pip install langchain-cli poetry
```

```bash uv
uv add langchain-cli poetry
```
</CodeGroup>

Next, come up with a name for your package. For this guide, we'll use `langchain-parrot-link`.
You can confirm that the name is available on PyPi by searching for it on the [PyPi website](https://pypi.org/).

Next, create your new Python package with `langchain-cli`, and navigate into the new directory with `cd`:

```bash
langchain-cli integration new

> The name of the integration to create (e.g., `my-integration`): parrot-link
> Name of integration in PascalCase [ParrotLink]:

cd parrot-link
```

Next, add any dependencies:

```bash
poetry add my-integration-sdk
```

We can also add some `typing` or `test` dependencies in a separate Poetry dependency group.

```
poetry add --group typing my-typing-dep
poetry add --group test my-test-dep
```

And finally, have Poetry set up a virtual environment with your dependencies, as well as your integration package:

```bash
poetry install --with lint,typing,test,test_integration
```

You now have a new Python package with a template for LangChain components. This template comes with files for each integration type, but you can duplicate or delete any of these files as needed (including the associated test files). You can create individual files with commands like this:

```bash
langchain-cli integration new \
    --name parrot-link \
    --name-class ParrotLink \
    --src integration_template/chat_models.py \
    --dst langchain_parrot_link/chat_models_2.py
```

</Accordion>

<Accordion title="Option 2: Poetry (manual)">

In this guide, we will be using [Poetry](https://python-poetry.org/) for dependency management and packaging, but you can use other tools you prefer.

### Prerequisites

- [GitHub](https://github.com) account
- [PyPi](https://pypi.org/) account

### Bootstrapping a new Python package with Poetry

First, install Poetry:

<CodeGroup>
```bash pip
pip install poetry
```

```bash uv
uv add poetry
```
</CodeGroup>

Next, come up with a name for your package. For this guide, we'll use `langchain-parrot-link`.
You can confirm that the name is available on PyPi by searching for it on the [PyPi website](https://pypi.org/).

Next, create your new Python package with Poetry, and navigate into the new directory with `cd`:

```bash
poetry new langchain-parrot-link
cd langchain-parrot-link
```

Add main dependencies using Poetry, which will add them to your `pyproject.toml` file:

```bash
poetry add langchain-core
```

We will also add some `test` dependencies in a separate Poetry dependency group. If
you are not using Poetry, we recommend adding these in a way that won't package them
with your published package, or just installing them separately when you run tests.

`langchain-tests` will provide the [standard tests](./standard_tests) we will use later.
We recommended pinning these to the latest version: <img src="https://img.shields.io/pypi/v/langchain-tests" style={{position:"relative",top:4,left:3}} />

<Note>
Replace `<latest_version>` with the latest version of `langchain-tests` below.
</Note>

```bash
poetry add --group test pytest pytest-socket pytest-asyncio langchain-tests==<latest_version>
```

And finally, have Poetry set up a virtual environment with your dependencies, as well
as your integration package:

```bash
poetry install --with test
```


### Writing your integration

Let's say you're building an integration package that provides a `ChatParrotLink` chat model integration for LangChain. Here's an example of what your project structure might look like:

```plaintext
langchain-parrot-link/
├── langchain_parrot_link/
│   ├── __init__.py
│   └── chat_models.py
├── tests/
│   ├── __init__.py
│   └── test_chat_models.py
├── pyproject.toml
└── README.md
```

All of these files should already exist from step 1, except for `chat_models.py` and `test_chat_models.py`. We will implement `test_chat_models.py` later, following the [standard tests](./standard_tests) guide.

For `chat_models.py`, paste the contents of the chat model implementation
[above](#implementing-langchain-components).

</Accordion>

### Push your package to a public Github repository

This is only required if you want to publish your integration in the LangChain documentation.

1. Create a new repository on GitHub.
2. Push your code to the repository.
3. Confirm that your repository is viewable by the public (e.g., in a private browsing window, where you're not logged into GitHub).

## Implementing LangChain components

LangChain components are subclasses of base classes in `langchain-core`.
Examples include chat models, vector stores, tools, embedding models, and retrievers.

Your integration package will typically implement a subclass of at least one of these
components. Expand the tabs below to see details on each.

<Tabs>

        <Tab title="Chat models">

        You can start from the following template or `langchain-cli` command:

        ```bash
        langchain-cli integration new \
            --name parrot-link \
            --name-class ParrotLink \
            --src integration_template/chat_models.py \
            --dst langchain_parrot_link/chat_models.py
        ```

        You can find example starter chat model code [here](https://github.com/langchain-ai/langchain/blob/master/libs/cli/langchain_cli/integration_template/integration_template/chat_models.py).

        </Tab>
        <Tab title="Vector stores">

        Your vector store implementation will depend on your chosen database technology.
        `langchain-core` includes a minimal
        [in-memory vector store](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html)
        that we can use as a guide. You can access the code [here](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/vectorstores/in_memory.py).

        All vector stores must inherit from the [VectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.base.VectorStore.html)
        base class. This interface consists of methods for writing, deleting and searching
        for documents in the vector store.

        `VectorStore` supports a variety of synchronous and asynchronous search types (e.g.,
        nearest-neighbor or maximum marginal relevance), as well as interfaces for adding
        documents to the store. See the [API Reference](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.base.VectorStore.html)
        for all supported methods. The required methods are tabulated below:

        | Method         | Description                                          |
        |------------------------ |------------------------------------------------------|
        | `add_documents`         | Add documents to the vector store.                   |
        | `delete`                | Delete selected documents from vector store (by IDs). |
        | `get_by_ids`            | Get selected documents from vector store (by IDs).    |
        | `similarity_search`     | Get documents most similar to a query.               |
        | `embeddings` (property) | Embeddings object for vector store.                  |
        | `from_texts`            | Instantiate vector store via adding texts.           |

        Note that `InMemoryVectorStore` implements some optional search types, as well as
        convenience methods for loading and dumping the object to a file, but this is not
        necessary for all implementations.

                <Tip>

                The [in-memory vector store](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/vectorstores/in_memory.py)
                is tested against the standard tests in the LangChain GitHub repository.

                </Tip>

        You can find example starter vector store code [here](https://github.com/langchain-ai/langchain/blob/master/libs/cli/langchain_cli/integration_template/integration_template/vectorstores.py).

        </Tab>
        <Tab title="Embeddings">

Embeddings are used to convert `str` objects from `Document.page_content` fields
into a vector representation (represented as a list of floats).

You can start from the following template or `langchain-cli` command:

```bash
langchain-cli integration new \
    --name parrot-link \
    --name-class ParrotLink \
    --src integration_template/embeddings.py \
    --dst langchain_parrot_link/embeddings.py
```

        You can find example starter embeddings code [here](https://github.com/langchain-ai/langchain/blob/master/libs/cli/langchain_cli/integration_template/integration_template/embeddings.py).

        </Tab>
        <Tab title="Tools">

Tools are used in 2 main ways:

1. To define an input schema or args schema to pass to a chat model's tool calling
feature along with a text request, such that the chat model can generate a tool call,
or parameters to call the tool with.
2. To take a tool call as generated above, and take some action and return a response
that can be passed back to the chat model as a `ToolMessage`.

The `Tools` class must inherit from the [BaseTool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.base.BaseTool.html#langchain_core.tools.base.BaseTool) class. This interface has 3 properties and 2 methods that should be implemented in a
subclass.

| Method         | Description                                          |
|------------------------ |------------------------------------------------------|
| `name`                  | Name of the tool (passed to the LLM too).            |
| `description`           | Description of the tool (passed to the LLM too).     |
| `args_schema`           | Define the schema for the tool's input arguments.    |
| `_run`                  | Run the tool with the given arguments.               |
| `_arun`                 | Asynchronously run the tool with the given arguments.|

### Properties

`name`, `description`, and `args_schema` are all properties that should be implemented
in the subclass. `name` and `description` are strings that are used to identify the tool
and provide a description of what the tool does. Both of these are passed to the LLM,
and users may override these values depending on the LLM they are using as a form of
prompt engineering. Giving these a concise and LLM-usable name and description is
important for the initial user experience of the tool.

`args_schema` is a Pydantic `BaseModel` that defines the schema for the tool's input
arguments. This is used to validate the input arguments to the tool, and to provide
a schema for the LLM to fill out when calling the tool. Similar to the `name` and
`description` of the overall Tool class, the fields' names (the variable name) and
description (part of `Field(..., description="description")`) are passed to the LLM,
and the values in these fields should be concise and LLM-usable.

### Run methods

`_run` is the main method that should be implemented in the subclass. This method
takes in the arguments from `args_schema` and runs the tool, returning a string
response. This method is usually called in a LangGraph [ToolNode](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/), and can also be called in a legacy
`langchain.agents.AgentExecutor`.

`_arun` is optional because by default, `_run` will be run in an async executor.
However, if your tool is calling any APIs or doing any async work, you should implement
this method to run the tool asynchronously in addition to `_run`.

### Implementation

You can start from the following template or `langchain-cli` command:

```bash
langchain-cli integration new \
    --name parrot-link \
    --name-class ParrotLink \
    --src integration_template/tools.py \
    --dst langchain_parrot_link/tools.py
```

        You can find example starter tool code [here](https://github.com/langchain-ai/langchain/blob/master/libs/cli/langchain_cli/integration_template/integration_template/tools.py).

        </Tab>
        <Tab title="Retrievers">

Retrievers are used to retrieve documents from APIs, databases, or other sources
based on a query. The `Retriever` class must inherit from the [BaseRetriever](https://python.langchain.com/api_reference/core/retrievers/langchain_core.retrievers.BaseRetriever.html) class. This interface has 1 attribute and 2 methods that should be implemented in a subclass.

| Method         | Description                                          |
|------------------------ |------------------------------------------------------|
| `k`                     | Default number of documents to retrieve (configurable). |
| `_get_relevant_documents`| Retrieve documents based on a query.                 |
| `_aget_relevant_documents`| Asynchronously retrieve documents based on a query.  |

### Attributes

`k` is an attribute that should be implemented in the subclass. This attribute
can be defined at the top of the class with a default value like
`k: int = 5`. This attribute is the default number of documents to retrieve
from the retriever, and can be overridden by the user when constructing or calling
the retriever.

### Methods

`_get_relevant_documents` is the main method that should be implemented in the subclass.

This method takes in a query and returns a list of `Document` objects, which have 2
main properties:

- `page_content` - the text content of the document
- `metadata` - a dictionary of metadata about the document

Retrievers are typically directly invoked by a user, e.g., as
`MyRetriever(k=4).invoke("query")`, which will automatically call `_get_relevant_documents`
under the hood.

`_aget_relevant_documents` is optional because by default, and `_get_relevant_documents` will be run in an async executor. However, if your retriever is calling any APIs or doing async work, you should implement this method to run the retriever asynchronously in addition to `_get_relevant_documents` for performance reasons.

### Implementation

You can start from the following template or `langchain-cli` command:

```bash
langchain-cli integration new \
    --name parrot-link \
    --name-class ParrotLink \
    --src integration_template/retrievers.py \
    --dst langchain_parrot_link/retrievers.py
```

        You can find example starter retriever code [here](https://github.com/langchain-ai/langchain/blob/master/libs/cli/langchain_cli/integration_template/integration_template/retrievers.py).

        </Tab>
</Tabs>

---

## Next steps

Now that you've implemented your package, you can move on to [testing your integration](./standard_tests).
