---
title: UI
---

import AlphaCallout from '/snippets/alpha-lg-callout.mdx';

<AlphaCallout />

You can use a prebuilt chat UI for interacting with any LangChain agent through the [Agent Chat UI](https://github.com/langchain-ai/agent-chat-ui). Using the [deployed version](https://agentchat.vercel.app) is the quickest way to get started, and allows you to interact with both local and deployed graphs.

## Run agent in UI

First, set up LangGraph API server [locally](/oss/python/langgraph/local-server) or deploy your agent on [LangGraph Platform](/langgraph-platform/quick-start-studio).

Then, navigate to [Agent Chat UI](https://agentchat.vercel.app), or clone the repository and [run the dev server locally](https://github.com/langchain-ai/agent-chat-ui?tab=readme-ov-file#setup).

<Tip>
UI has out-of-box support for rendering tool calls, and tool result messages. To customize what messages are shown, see the [Hiding Messages in the Chat](https://github.com/langchain-ai/agent-chat-ui?tab=readme-ov-file#hiding-messages-in-the-chat) section in the Agent Chat UI documentation.
</Tip>

## Add human-in-the-loop

TODO

## Generative UI

TODO
