---
title: Self-hosted LangSmith Platform deployments
sidebarTitle: Overview
---

<Note>
**Important**<br></br>
Self-hosted LangSmith is an add-on to the Enterprise plan designed for our largest, most security-conscious customers. For more details, refer to [Pricing](https://www.langchain.com/pricing). [Contact our sales team](https://www.langchain.com/contact-sales) if you want to get a license key to trial LangSmith in your environment.
</Note>

LangSmith supports different self-hosted configurations depending on your scale, security, and infrastructure needs. This page provides an overview of the supported deployment types.

The self-hosted deployment type allows you to run all components entirely within your own cloud environment. You can choose between the following deployment models:

1. [**LangSmith Platform**](#langsmith-platform): Deploy an instance of the LangSmith application that includes observability, tracing, and evaluations in the UI and API. Best for teams who want self-hosted monitoring and evaluation without deploying agents.
1. **[Graph/agent deployment](#full-platform)**: Deploy a _graph_ (workflow or agentic) to LangGraph Server via the control plane. The control plane and data plane form the full LangSmith platform, providing UI and API management for running and monitoring agents. This includes observability, evaluation, and deployment management.
1. **[Standalone server deployment](#standalone-server)**: Deploy a LangGraph Server directly without the control plane UI. Ideal for lightweight setups running one or a few agents as independent services, with full control over scaling and integration.s

## Comparison

Deployment model | Includes | Best for | Deployment methods
------------------|------------------|----------|--------------------
**LangSmith Platform** | <ul><li>LangSmith app (UI + API)</li><li>Backend services (queue, playground, ACE)</li><li>Datastores: PostgreSQL, Redis, ClickHouse, optional blob storage</li></ul> | <ul><li>Teams who need self-hosted observability, tracing, and evaluation</li><li>Running the LangSmith app without deploying agents/graphs</li></ul> | <ul><li>Docker Compose (dev/test)</li><li>Kubernetes + Helm (production)</li></ul>
**Graph/Agent Deployment** | <ul><li>Everything from LangSmith Platform</li><li>Control plane (deployments UI, revision management, LangGraph Studio)</li><li>Data plane (LangGraph Server pods)</li><li>Kubernetes operator for orchestration</li></ul> | <ul><li>Enterprise teams needing a private LangChain Cloud</li><li>Centralized UI/API for managing multiple agents/graphs</li><li>Integrated observability and orchestration</li></ul> | <ul><li>Kubernetes with Helm (required)</li><li>Runs on EKS, GKE, AKS, or self-managed clusters</li></ul>
**Standalone Server Deployment** | <ul><li>LangGraph Server container(s)</li><li>Requires PostgreSQL + Redis (shared or dedicated)</li><li>Optional LangSmith integration for tracing</li></ul> | <ul><li>Lightweight deployments of one or a few agents</li><li>Integrating LangGraph Servers as microservices</li><li>Teams preferring to manage scaling & CI/CD themselves</li></ul> | <ul><li>Docker / Docker Compose (dev/test)</li><li>Kubernetes + Helm (production)</li><li>Any container runtime or VM (ECS, EC2, ACI, etc.)</li></ul>



<Note>
For a guide on deployment, refer to:

* [How to deploy the Self-Hosted Full Platform](/langgraph-platform/deploy-self-hosted-full-platform)
* [How to deploy the Self-Hosted Standalone Server](/langgraph-platform/deploy-standalone-server)

Supported Compute Platforms: [Kubernetes](https://kubernetes.io/) (for Control Plane), any compute platform (for Standalone Server Only)
</Note>

## LangSmith Platform

You can run LangSmith in Kubernetes (recommended) or Docker in a cloud environment that you control. The LangSmith application consists of several components including LangSmith servers and stateful services:

- [Services](#services)
  - LangSmith frontend
  - LangSmith backend
  - LangSmith platform backend
  - LangSmith Playground
  - LangSmith queue
  - LangSmith ACE (Arbitrary Code Execution) backend
- [Storage services](#storage-services)
  - ClickHouse
  - PostgreSQL
  - Redis
  - Blob storage (Optional, but recommended)

<img
    className="block dark:hidden"
    src="/langsmith/images/cloud-arch-light.png"
    alt="Light mode overview"
/>

<img
    className="hidden dark:block"
    src="/langsmith/images/cloud-arch-dark.png"
    alt="Dark mode overview"
/>

To access the LangSmith UI and send API requests, you will need to expose the [LangSmith frontend](#langsmith-frontend) service. Depending on your installation method, this can be a load balancer or a port exposed on the host machine.

### Storage services

<Note>
LangSmith Self-Hosted will bundle all storage services by default. You can configure LangSmith to use external versions of all storage services. In a production setting, we **strongly recommend using external storage services**.
</Note>

| Service | Description |
|---------|-------------|
| <a id="clickhouse"></a> **ClickHouse** | [ClickHouse](https://clickhouse.com/docs/en/intro) is a high-performance, column-oriented SQL database management system (DBMS) for online analytical processing (OLAP).<br/><br/>LangSmith uses ClickHouse as the primary data store for traces and feedback (high-volume data). |
| <a id="postgresql"></a> **PostgreSQL** | [PostgreSQL](https://www.postgresql.org/about/) is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads.<br/><br/>LangSmith uses PostgreSQL as the primary data store for transactional workloads and operational data (almost everything besides traces and feedback). |
| <a id="redis"></a> **Redis** | [Redis](https://github.com/redis/redis) is a powerful in-memory key-value database that persists on disk. By holding data in memory, Redis offers high performance for operations like caching.<br/><br/>LangSmith uses Redis to back queuing and caching operations. |
| <a id="blob-storage"></a> **Blob storage** | LangSmith supports several blob storage providers, including [AWS S3](https://aws.amazon.com/s3/), [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/), and [Google Cloud Storage](https://cloud.google.com/storage).<br/><br/>LangSmith uses blob storage to store large files, such as trace artifacts, feedback attachments, and other large data objects. Blob storage is optional, but highly recommended for production deployments. |

### Services

| Service | Description |
|---------|-------------|
| <a id="langsmith-frontend"></a> **LangSmith frontend** | The frontend uses Nginx to serve the LangSmith UI and route API requests to the other servers. This serves as the entrypoint for the application and is the only component that must be exposed to users. |
| <a id="langsmith-backend"></a> **LangSmith backend** | The backend is the main entrypoint for CRUD API requests and handles the majority of the business logic for the application. This includes handling requests from the frontend and SDK, preparing traces for ingestion, and supporting the hub API. |
| <a id="langsmith-queue"></a> **LangSmith queue** | The queue handles incoming traces and feedback to ensure that they are ingested and persisted into the traces and feedback datastore asynchronously, handling checks for data integrity and ensuring successful insert into the datastore, handling retries in situations such as database errors or the temporary inability to connect to the database. |
| <a id="langsmith-platform-backend"></a> **LangSmith platform backend** | The platform backend is another critical service that primarily handles authentication, run ingestion, and other high-volume tasks. |
| <a id="langsmith-playground"></a> **LangSmith playground** | The playground is a service that handles forwarding requests to various LLM APIs to support the LangSmith Playground feature. This can also be used to connect to your own custom model servers. |
| <a id="langsmith-ace-arbitrary-code-execution-backend"></a> **LangSmith ACE (Arbitrary Code Execution) backend** | The ACE backend is a service that handles executing arbitrary code in a secure environment. This is used to support running custom code within LangSmith. |

## Graph and agent deployment

The _Graph and agent deployment_ model builds on top of the [**LangSmith Platform deployment**](#langsmith-platform). This model is ideal for enterprise teams who want a centralized, UI-driven platform to manage multiple agents and graphs, with all infrastructure, data, and orchestration fully under their control.

You must already have a self-hosted LangSmith instance installed in your cloud. Once you have a LangSmith instance, you can enable deployments on top of it, which provides the control plane and data plane for running and managing agents.

You run both the control plane and the data plane entirely within your own infrastructure. You are responsible for provisioning and managing all components.

| Component      | Responsibilities | Where it runs | Who manages it |
|----------------|------------------|---------------|----------------|
| **Control plane** | <ul><li>UI for creating deployments & revisions</li><li>APIs for deployment management</li></ul> | Your cloud | You |
| **Data plane** | <ul><li>Operator/listener to reconcile deployments</li><li>LangGraph Servers (agents/graphs)</li><li>Backing services (Postgres, Redis, etc.)</li></ul> | Your cloud | You |

### Requirements

1. Use the `langgraph-cli` or Studio app to test your graph locally.
2. Build a Docker image with `langgraph build`.
3. Deploy your LangGraph Server via the LangSmith control plane UI or through your container tooling of choice.
4. All agents are deployed as Kubernetes services behind the ingress configured for your LangSmith instance.

### Architecture

![Self-Hosted Full Platform Architecture](/langgraph-platform/images/self-hosted-full-platform-architecture.png)

### Compute Platforms

- **Kubernetes**: The Full Platform deployment model supports deploying control plane and data plane infrastructure to any Kubernetes cluster.

<Tip>
If you would like to enable this on your LangSmith instance, please follow the [Self-Hosted Full Platform deployment guide](/langgraph-platform/deploy-self-hosted-full-platform).
</Tip>

## Standalone server deployment

The _Standalone server deployment_ model is the most lightweight and flexible way to run LangSmith Platform. Unlike the other models, you only manage a simplified data plane made up of LangGraph Servers and their required backing services (PostgreSQL, Redis, etc.).

This option is best for teams who want to run one or a few agents as independent services, or integrate LangGraph Servers as microservices into their own systems. It gives you full control over scaling, deployment, and CI/CD pipelines, while still allowing optional integration with LangSmith for tracing and evaluation.

<Warning>
Standalone server deployments should not be run in serverless environments. Scale-to-zero may cause task loss and scaling up will not work reliably.
</Warning>

| Component      | Responsibilities | Where it runs | Who manages it |
|----------------|------------------|---------------|----------------|
| **Control plane** | n/a | n/a | n/a |
| **Data plane** | <ul><li>LangGraph Servers</li><li>Postgres, Redis, etc.</li></ul> | Your cloud | You |

### Workflow

1. Define and test your graph locally using the `langgraph-cli` or Studio app.
2. Package your agent as a Docker image.
3. Deploy the LangGraph Server to your compute platform of choice (Kubernetes, Docker, VM).
4. Optionally, configure LangSmith API keys and endpoints so the server reports traces and evaluations back to LangSmith (self-hosted or SaaS).

---

### Architecture

![Standalone Container](/langgraph-platform/images/langgraph-platform-deployment-architecture.png)

---

### Supported Compute Platforms

- **Kubernetes**
  Use our Helm chart to deploy LangGraph Servers in a Kubernetes cluster. This is the recommended option for production-grade deployments.

- **Docker**
  Deploy to any Docker-supported compute platform (local dev machine, VM, ECS, etc.).
  This is best suited for development or small-scale workloads.

<Tip>
To deploy a [LangGraph Server](/langgraph-platform/langgraph-server), see the [how-to guide](/langgraph-platform/deploy-standalone-server).
</Tip>

