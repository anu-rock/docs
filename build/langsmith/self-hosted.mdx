---
title: Self-hosted LangSmith Platform deployments
sidebarTitle: Overview
---

<Note>
**Important**<br></br>
Self-hosted LangSmith is an add-on to the Enterprise plan designed for our largest, most security-conscious customers. For more details, refer to [Pricing](https://www.langchain.com/pricing). [Contact our sales team](https://www.langchain.com/contact-sales) if you want to get a license key to trial LangSmith in your environment.
</Note>

LangSmith supports different self-hosted configurations depending on your scale, security, and infrastructure needs. This page provides an overview of the supported deployment types.

The self-hosted deployment type allows you to run all components entirely within your own cloud environment. You can choose between the following deployment models:

1. [**LangSmith Platform**](#langsmith-platform): Deploy an instance of the LangSmith application that includes observability, tracing, and evaluations in the UI and API.
1. **[Graph/agent deployment](#full-platform)**: Deploy both the control plane and data plane for the full LangSmith platform with UI and API management capabilities.
1. **[Standalone server deployment](#standalone-server)**: Deploy a LangGraph Server directly without the control plane UI.

All self-hosted options share the same core components (API server, workers, Postgres, Redis, and object storage). What differs is how these services are packaged and deployed.

## Deployment comparison

Deployment model | Includes | Best for | Deployment methods
------------------|------------------|----------|--------------------
**LangSmith Platform** | <ul><li>LangSmith app (UI + API)</li><li>Backend services (queue, playground, ACE)</li><li>Datastores: PostgreSQL, Redis, ClickHouse, optional blob storage</li></ul> | <ul><li>Teams who need self-hosted observability, tracing, and evaluation</li><li>Running the LangSmith app without deploying agents/graphs</li></ul> | <ul><li>Docker Compose (dev/test)</li><li>Kubernetes + Helm (production)</li></ul>
**Graph/Agent Deployment** | <ul><li>Everything from LangSmith Platform</li><li>Control plane (deployments UI, revision management, LangGraph Studio)</li><li>Data plane (LangGraph Server pods)</li><li>Kubernetes operator for orchestration</li></ul> | <ul><li>Enterprise teams needing a private LangChain Cloud</li><li>Centralized UI/API for managing multiple agents/graphs</li><li>Integrated observability and orchestration</li></ul> | <ul><li>Kubernetes with Helm (required)</li><li>Runs on EKS, GKE, AKS, or self-managed clusters</li></ul>
**Standalone Server Deployment** | <ul><li>LangGraph Server container(s)</li><li>Requires PostgreSQL + Redis (shared or dedicated)</li><li>Optional LangSmith integration for tracing</li></ul> | <ul><li>Lightweight deployments of one or a few agents</li><li>Integrating LangGraph Servers as microservices</li><li>Teams preferring to manage scaling & CI/CD themselves</li></ul> | <ul><li>Docker / Docker Compose (dev/test)</li><li>Kubernetes + Helm (production)</li><li>Any container runtime or VM (ECS, EC2, ACI, etc.)</li></ul>



<Note>
For a guide on deployment, refer to:

* [How to deploy the Self-Hosted Full Platform](/langgraph-platform/deploy-self-hosted-full-platform)
* [How to deploy the Self-Hosted Standalone Server](/langgraph-platform/deploy-standalone-server)

Supported Compute Platforms: [Kubernetes](https://kubernetes.io/) (for Control Plane), any compute platform (for Standalone Server Only)
</Note>

## LangSmith Platform

You can run LangSmith in Kubernetes (recommended) or Docker in a cloud environment that you control. The LangSmith application consists of several components including LangSmith servers and stateful services:

- [Services](#services)
  - LangSmith frontend
  - LangSmith backend
  - LangSmith platform backend
  - LangSmith Playground
  - LangSmith queue
  - LangSmith ACE (Arbitrary Code Execution) backend
- [Storage services](#storage-services)
  - ClickHouse
  - PostgreSQL
  - Redis
  - Blob storage (Optional, but recommended)

<img
    className="block dark:hidden"
    src="/langsmith/images/cloud-arch-light.png"
    alt="Light mode overview"
/>

<img
    className="hidden dark:block"
    src="/langsmith/images/cloud-arch-dark.png"
    alt="Dark mode overview"
/>

To access the LangSmith UI and send API requests, you will need to expose the [LangSmith frontend](#langsmith-frontend) service. Depending on your installation method, this can be a load balancer or a port exposed on the host machine.

### Storage services

<Note>
LangSmith Self-Hosted will bundle all storage services by default. You can configure LangSmith to use external versions of all storage services. In a production setting, we **strongly recommend using external storage services**.
</Note>

| Service | Description |
|---------|-------------|
| <a id="clickhouse"></a> **ClickHouse** | [ClickHouse](https://clickhouse.com/docs/en/intro) is a high-performance, column-oriented SQL database management system (DBMS) for online analytical processing (OLAP).<br/><br/>LangSmith uses ClickHouse as the primary data store for traces and feedback (high-volume data). |
| <a id="postgresql"></a> **PostgreSQL** | [PostgreSQL](https://www.postgresql.org/about/) is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads.<br/><br/>LangSmith uses PostgreSQL as the primary data store for transactional workloads and operational data (almost everything besides traces and feedback). |
| <a id="redis"></a> **Redis** | [Redis](https://github.com/redis/redis) is a powerful in-memory key-value database that persists on disk. By holding data in memory, Redis offers high performance for operations like caching.<br/><br/>LangSmith uses Redis to back queuing and caching operations. |
| <a id="blob-storage"></a> **Blob storage** | LangSmith supports several blob storage providers, including [AWS S3](https://aws.amazon.com/s3/), [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/), and [Google Cloud Storage](https://cloud.google.com/storage).<br/><br/>LangSmith uses blob storage to store large files, such as trace artifacts, feedback attachments, and other large data objects. Blob storage is optional, but highly recommended for production deployments. |

### Services

| Service | Description |
|---------|-------------|
| <a id="langsmith-frontend"></a> **LangSmith frontend** | The frontend uses Nginx to serve the LangSmith UI and route API requests to the other servers. This serves as the entrypoint for the application and is the only component that must be exposed to users. |
| <a id="langsmith-backend"></a> **LangSmith backend** | The backend is the main entrypoint for CRUD API requests and handles the majority of the business logic for the application. This includes handling requests from the frontend and SDK, preparing traces for ingestion, and supporting the hub API. |
| <a id="langsmith-queue"></a> **LangSmith queue** | The queue handles incoming traces and feedback to ensure that they are ingested and persisted into the traces and feedback datastore asynchronously, handling checks for data integrity and ensuring successful insert into the datastore, handling retries in situations such as database errors or the temporary inability to connect to the database. |
| <a id="langsmith-platform-backend"></a> **LangSmith platform backend** | The platform backend is another critical service that primarily handles authentication, run ingestion, and other high-volume tasks. |
| <a id="langsmith-playground"></a> **LangSmith playground** | The playground is a service that handles forwarding requests to various LLM APIs to support the LangSmith Playground feature. This can also be used to connect to your own custom model servers. |
| <a id="langsmith-ace-arbitrary-code-execution-backend"></a> **LangSmith ACE (Arbitrary Code Execution) backend** | The ACE backend is a service that handles executing arbitrary code in a secure environment. This is used to support running custom code within LangSmith. |

## Graph and agent deployment

The Full Platform deployment model is a fully self-hosted solution where you manage both the [control plane](/langgraph-platform/control-plane) and [data plane](/langgraph-platform/data-plane) in your cloud. This option gives you full control and responsibility of the control plane and data plane infrastructure.

|                   | [Control plane](/langgraph-platform/control-plane) | [Data plane](/langgraph-platform/data-plane) |
|-------------------|-------------------|------------|
| **What is it?** | <ul><li>Control plane UI for creating deployments and revisions</li><li>Control plane APIs for creating deployments and revisions</li></ul> | <ul><li>Data plane "listener" for reconciling deployments with control plane state</li><li>LangGraph Servers</li><li>Postgres, Redis, etc</li></ul> |
| **Where is it hosted?** | Your cloud | Your cloud |
| **Who provisions and manages it?** | You | You |

### Requirements

* You use `langgraph-cli` and/or [Studio](/langgraph-platform/langgraph-studio) app to test graph locally.
* You use `langgraph build` command to build image.
* You have a Self-Hosted LangSmith instance deployed.
* You are using [Ingress](/langsmith/self-host-ingress) for your LangSmith instance. All agents will be deployed as Kubernetes services behind this ingress.

With the full platform option, build a Docker image using the [LangGraph CLI](/langgraph-platform/langgraph-cli) and deploy your LangGraph Server from the [control plane UI](/langgraph-platform/control-plane#control-plane-ui) or using the container deployment tooling of your choice.

### Architecture

![Self-Hosted Full Platform Architecture](/langgraph-platform/images/self-hosted-full-platform-architecture.png)

### Compute Platforms

* **Kubernetes**: The Full Platform deployment model supports deploying control plane and data plane infrastructure to any Kubernetes cluster.

<Tip>
If you would like to enable this on your LangSmith instance, please follow the [Self-Hosted Full Platform deployment guide](/langgraph-platform/deploy-self-hosted-full-platform).
</Tip>

## Standalone Server

### Overview

The Standalone Server Only deployment model is the least restrictive option for deployment. There is no [control plane](/langgraph-platform/control-plane). A simplified version of the [Data plane](/langgraph-platform/data-plane) infrastructure is managed by you.

|                   | [Control plane](/langgraph-platform/control-plane) | [Data plane](/langgraph-platform/data-plane) |
|-------------------|-------------------|------------|
| **What is it?** | n/a | <ul><li>LangGraph Servers</li><li>Postgres, Redis, etc</li></ul> |
| **Where is it hosted?** | n/a | Your cloud |
| **Who provisions and manages it?** | n/a | You |

<Warning>
LangGraph Platform should not be deployed in serverless environments. Scale to zero may cause task loss and scaling up will not work reliably.
</Warning>

### Architecture

![Standalone Container](/langgraph-platform/images/langgraph-platform-deployment-architecture.png)

### Compute Platforms

#### Kubernetes

The Standalone Server deployment model supports deploying data plane infrastructure to a Kubernetes cluster.

#### Docker

The Standalone Server deployment model supports deploying data plane infrastructure to any Docker-supported compute platform.

<Tip>
To deploy a [LangGraph Server](/langgraph-platform/langgraph-server), follow the how-to guide for [how to deploy the Standalone Server](/langgraph-platform/deploy-standalone-server).
</Tip>
