---
title: Quickstart
---

import AlphaCallout from '/snippets/alpha-lc-callout.mdx';

<AlphaCallout />

Super quick start
:::python
```python
from langchain.agents import create_react_agent

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

agent = create_react_agent(
    model="anthropic:claude-3-7-sonnet-latest",
    tools=[get_weather],
    prompt="You are a helpful assistant",
)

# Run the agent
agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather in sf"}]}
)
```
:::

:::js
```ts
import { createReactAgent, tool } from "langchain";

const getWeather = tool((city: string) => `It's always sunny in ${city}!`, {
  name: "get_weather",
  description: "Get the weather for a given city",
});

const agent = createReactAgent({
  model: "anthropic:claude-3-7-sonnet-latest",
  tools: [getWeather],
});

console.log(
  await agent.invoke({
    messages: [{ role: "user", content: "What's the weather in Tokyo?" }],
  })
);
```
:::

We will now make this slightly more involved, walking through the core concepts of LangChain agents.
Specifically, we will:
1. Add a more detailed prompt
2. Add more real-world tools that read from external data sources
3. Configure more model settings
4. Set a response format
5. Add in conversational memory so we can chat

:::python
```python
# Step 1: define system prompt

system_prompt = """You are an expert weather forecaster, who speaks in puns.

You have access to two tools:

- get_weather_for_location: use this to get the weather for a specific location
- get_user_location: use this to get the user's location

If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean whereever they are, use the get_user_location tool to find their location."""

# Step 2: define tools
from langchain_core.tools import tool

def get_weather(city: str) -> str:  # (1)!
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

from langchain_core.runnables import RunnableConfig

USER_LOCATION = {
    "1": "Florida",
    "2": "SF"
}

@tool
def get_user_info(config: RunnableConfig) -> str:
    """Retrieve user information based on user ID."""
    user_id = config["context"].get("user_id")
    return USER_LOCATION[user_id]


# Step 3: define model

from langchain.chat_models import init_chat_model

model = init_chat_model(
    "anthropic:claude-3-7-sonnet-latest",
    temperature=0
)

# Step 4: define response format

from dataclasses import dataclass

@dataclass
class WeatherResponse:
    conditions: str
    punny_response: str

# Step 5: define checkpointer
from langgraph.checkpoint.memory import InMemorySaver

checkpointer = InMemorySaver()

# Step 6: create agent
agent = create_agent(
    model=model,
    prompt=system_prompt,
    tools=[get_user_info, get_weather],
    response_format=WeatherResponse,
    checkpointer=checkpointer
)

config = {"configurable": {"thread_id": "1"}}
context = {"user_id": "1"}
response = agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather outside?"}]},
    config=config,
    context=context
)

response['structured_response']

response = agent.invoke(
    {"messages": [{"role": "user", "content": "thank you!"}]},
    config=config,
    context=context
)

response['structured_response']
```
:::

:::js
```ts
import { tool, createReactAgent, MemorySaver } from "langchain";
import z from "zod";

// Step 1: define system prompt
const systemPrompt = `You are an expert weather forecaster, who speaks in puns.

You have access to two tools:

- get_weather_for_location: use this to get the weather for a specific location
- get_user_location: use this to get the user's location

If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean whereever they are, use the get_user_location tool to find their location.`;

// Step 2: define tools
const getWeather = tool(({ city }) => `It's always sunny in ${city}!`, {
  name: "get_weather",
  description: "Get the weather for a given city",
  schema: z.object({
    city: z.string(),
  }),
});

const USER_LOCATION = {
  "1": "Florida",
  "2": "SF",
} as const;

const getUserInfo = tool(
  (_, config) => {
    const { user_id } = config.context as {
      user_id: keyof typeof USER_LOCATION;
    };
    console.log("user_id", config.context);
    return USER_LOCATION[user_id];
  },
  {
    name: "get_user_info",
    description: "Retrieve user information based on user ID",
    schema: z.object({}),
  }
);

// Step 3: define response format
const responseFormat = z.object({
  conditions: z.string(),
  punny_response: z.string(),
});

// Step 4: define checkpointer
const checkpointer = new MemorySaver();

// Step 5: create agent
const agent = createReactAgent({
  model: "anthropic:claude-3-7-sonnet-latest",
  prompt: systemPrompt,
  tools: [getUserInfo, getWeather],
  responseFormat,
  checkpointer,
});

const config = {
  configurable: { thread_id: "1" },
  context: { user_id: "1" },
};
const response = await agent.invoke(
  { messages: [{ role: "user", content: "what is the weather outside?" }] },
  config
);
console.log(response.structuredResponse);

const thankYouResponse = await agent.invoke(
  { messages: [{ role: "user", content: "thank you!" }] },
  config
);
console.log(thankYouResponse.structuredResponse);
```
:::