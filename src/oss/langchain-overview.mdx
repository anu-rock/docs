---
title: Overview
---

:::python
<Warning>
LangChain v1 is under active development and is not recommended for production use.
* APIs may change without notice
* The docs are incomplete and subject to change

For the latest stable version, see the v0 [LangChain](https://python.langchain.com/docs/introduction/) docs.
</Warning>
:::

:::js
<Warning>
LangChain v1 is under active development and is not recommended for production use.
* APIs may change without notice
* The docs are incomplete and subject to change

For the latest stable version, see the v0 [LangChain](https://js.langchain.com/docs/introduction/) docs.
</Warning>
:::

LangChain is the easiest way to start building with LLMs, letting you get started on building agents with OpenAI, Anthropic, Google, and more in under 10 lines of code.

LangChain [agents](/oss/langchain-agents) are built on top of [LangGraph](/oss/langgraph/overview) in order to provide durable execution, streaming, human-in-the-loop, persistence. You do not need to know LangGraph for basic LangChain agent usage.

## <Icon icon="download" size={20} /> Install

:::python
<CodeGroup>
```bash pip
pip install --pre -U langchain
```

```bash uv
uv add langchain@pre
```
</CodeGroup>
:::
:::js
<CodeGroup>
```bash npm
npm install langchain@next
```

```bash pnpm
pnpm add langchain@next
```

```bash yarn
yarn add langchain@next
```

```bash bun
bun add langchain@next
```
</CodeGroup>
:::

## Create an agent

:::python
```python
# pip install -qU "langchain[anthropic]" to call the model

from langchain.agents import create_agent

def get_weather(city: str) -> str:
    """Get weather for a given city."""
    return f"It's always sunny in {city}!"

agent = create_agent(
    model="anthropic:claude-3-7-sonnet-latest",
    tools=[get_weather],
    prompt="You are a helpful assistant",
)

# Run the agent
agent.invoke(
    {"messages": [{"role": "user", "content": "what is the weather in sf"}]}
)
```
:::

:::js
```ts
import { z } from "zod";
// npm install @langchain/anthropic to call the model
import { createAgent, tool } from "langchain";

const getWeather = tool(({ city }) => `It's always sunny in ${city}!`, {
  name: "get_weather",
  description: "Get the weather for a given city",
  schema: z.object({
    city: z.string(),
  }),
});

const agent = createAgent({
  model: "anthropic:claude-3-7-sonnet-latest",
  tools: [getWeather],
});

console.log(
  await agent.invoke({
    messages: [{ role: "user", content: "What's the weather in Tokyo?" }],
  })
);
```
:::


## Core benefits

<Columns cols={2}>
  <Card title="Standard Model Interface" icon="arrows-rotate" href="/langchain-models" arrow cta="Learn more">
    Different model providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models to allow you to seamlessly swap providers and avoid lock in.
  </Card>

  <Card title="Easy to use, yet highly flexible agent" icon="wand-magic-sparkles" href="/langchain-agents" arrow cta="Learn more">
    LangChain's agent abstraction is designed to be easy to get started with - letting you build a simple agent in ~10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.
  </Card>

  <Card title="Built on top of LangGraph" icon="circle-nodes" href="/oss/langgraph/overview" arrow cta="Learn more">
    LangChain's agents are built on top of LangGraph. This allows us to take advantage of LangGraph's durable execution, human-in-the-loop support, persistence, and more.
  </Card>

  <Card title="Debugging with LangSmith" icon="eye" href="/langsmith/home" arrow cta="Learn more">
    Gain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.
  </Card>
</Columns>